{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Forecasting using Transformers\n",
    "\n",
    "In this notebook we implement a Transformer model to forecast stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # https://stackoverflow.com/a/64438413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time2Vec Embedding\n",
    "\n",
    "https://arxiv.org/abs/1907.05321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(keras.layers.Layer):\n",
    "    def __init__(self, kernel_size: int, activation: str = 'sin', **kwargs):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            kernel_size (int): Length of the time embedding vector.\n",
    "            activation (str, optional): Periodic activation function. Possible values are ['sin', 'cos']. Defaults to 'sin'.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.k = kernel_size\n",
    "\n",
    "    def build(self, input_shape: list[int]):\n",
    "\n",
    "        # Weight and bias terms for linear portion (i = 0)\n",
    "        # of embedding.\n",
    "        self.w_linear = self.add_weight(\n",
    "            name='w_linear',\n",
    "            shape=(1,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b_linear = self.add_weight(\n",
    "            name='b_linear',\n",
    "            shape=(1,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Weight and bias terms for the periodic\n",
    "        # portion (1 <= i <= k) of embedding.\n",
    "        self.w_periodic = self.add_weight(\n",
    "            name='w_periodic',\n",
    "            shape=(self.k,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b_periodic = self.add_weight(\n",
    "            name='b_periodic',\n",
    "            shape=(self.k,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e27c2da514be0f4555df3a4c15a4c6256ef40203ad64abea68e2343d203af1e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
