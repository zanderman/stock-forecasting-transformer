{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Forecasting using Transformers\n",
    "\n",
    "In this notebook we implement a Transformer model to forecast stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # https://stackoverflow.com/a/64438413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time2Vec Embedding\n",
    "\n",
    "https://arxiv.org/abs/1907.05321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp.shape=TensorShape([None, 128, 2])\n",
      "x.shape=TensorShape([None, 128, 33])\n",
      "x.shape=TensorShape([None, 128, 35])\n"
     ]
    }
   ],
   "source": [
    "class Time2Vec(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim: int, activation: str = 'sin', **kwargs):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): Length of the time embedding vector.\n",
    "            activation (str, optional): Periodic activation function. Possible values are ['sin', 'cos']. Defaults to 'sin'.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.activation = activation.lower() # Convert to lower-case.\n",
    "\n",
    "        # Set periodic activation function.\n",
    "        if self.activation.startswith('sin'):\n",
    "            self.activation_func = tf.sin\n",
    "        elif self.activation.startswith('cos'):\n",
    "            self.activation_func = tf.cos\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported periodic activation function \"{activation}\"')\n",
    "\n",
    "    def build(self, input_shape: list[int]):\n",
    "\n",
    "        # Weight and bias term for linear portion (i = 0)\n",
    "        # of embedding.\n",
    "        self.w_linear = self.add_weight(\n",
    "            name='w_linear',\n",
    "            shape=(input_shape[1], 1,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b_linear = self.add_weight(\n",
    "            name='b_linear',\n",
    "            shape=(input_shape[1], 1,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Weight and bias terms for the periodic\n",
    "        # portion (1 <= i <= k) of embedding.\n",
    "        self.w_periodic = self.add_weight(\n",
    "            name='w_periodic',\n",
    "            shape=(input_shape[-1], self.embed_dim,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b_periodic = self.add_weight(\n",
    "            name='b_periodic',\n",
    "            shape=(input_shape[1], self.embed_dim,),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): Input tensor with shape (batch_size, sequence_length, feature_size)\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Output tensor with shape (batch_size, sequence_length, embed_dim + 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # Linear term (i = 0).\n",
    "        embed_linear = tf.tensordot(x, self.w_linear, axes=1) + self.b_linear\n",
    "\n",
    "        # Periodic terms (1 <= i <= k).\n",
    "        inner = tf.tensordot(x, self.w_periodic, axes=1) + self.b_periodic\n",
    "        embed_periodic = self.activation_func(inner)\n",
    "\n",
    "        # Return concatenated linear and periodic features.\n",
    "        return tf.concat([embed_linear, embed_periodic], axis=-1)\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Retreive custom layer configuration for future loading.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configuration dictionary.\n",
    "        \"\"\"\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'activation': self.activation,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "stock_feat = 2\n",
    "seq_len = 128\n",
    "embed_dim = 32\n",
    "inp = keras.Input(shape=(seq_len, stock_feat))\n",
    "print(f\"{inp.shape=}\")\n",
    "x = Time2Vec(embed_dim)(inp)\n",
    "print(f\"{x.shape=}\")\n",
    "x = keras.layers.Concatenate(axis=-1)([inp, x])\n",
    "print(f\"{x.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e27c2da514be0f4555df3a4c15a4c6256ef40203ad64abea68e2343d203af1e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
